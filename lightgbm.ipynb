{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>serial_number</th>\n",
       "      <th>model</th>\n",
       "      <th>capacity_bytes</th>\n",
       "      <th>failure</th>\n",
       "      <th>smart_1_normalized</th>\n",
       "      <th>smart_1_raw</th>\n",
       "      <th>smart_2_normalized</th>\n",
       "      <th>smart_2_raw</th>\n",
       "      <th>smart_3_normalized</th>\n",
       "      <th>...</th>\n",
       "      <th>smart_250_normalized</th>\n",
       "      <th>smart_250_raw</th>\n",
       "      <th>smart_251_normalized</th>\n",
       "      <th>smart_251_raw</th>\n",
       "      <th>smart_252_normalized</th>\n",
       "      <th>smart_252_raw</th>\n",
       "      <th>smart_254_normalized</th>\n",
       "      <th>smart_254_raw</th>\n",
       "      <th>smart_255_normalized</th>\n",
       "      <th>smart_255_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-02-11</td>\n",
       "      <td>MJ0351YNG9VAJA</td>\n",
       "      <td>Hitachi HDS5C3030ALA630</td>\n",
       "      <td>3.000593e+12</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-03-16</td>\n",
       "      <td>Z3016SZJ</td>\n",
       "      <td>ST4000DM000</td>\n",
       "      <td>4.000787e+12</td>\n",
       "      <td>0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>113638200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>W300CDRJ</td>\n",
       "      <td>ST4000DM000</td>\n",
       "      <td>4.000787e+12</td>\n",
       "      <td>0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>210314536.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-02-09</td>\n",
       "      <td>W300AWBZ</td>\n",
       "      <td>ST4000DM000</td>\n",
       "      <td>4.000787e+12</td>\n",
       "      <td>0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>167638104.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-03-03</td>\n",
       "      <td>MJ1311YNG6XKGA</td>\n",
       "      <td>Hitachi HDS5C3030ALA630</td>\n",
       "      <td>3.000593e+12</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   serial_number                    model  capacity_bytes  \\\n",
       "0  2015-02-11  MJ0351YNG9VAJA  Hitachi HDS5C3030ALA630    3.000593e+12   \n",
       "1  2015-03-16        Z3016SZJ              ST4000DM000    4.000787e+12   \n",
       "2  2015-12-01        W300CDRJ              ST4000DM000    4.000787e+12   \n",
       "3  2015-02-09        W300AWBZ              ST4000DM000    4.000787e+12   \n",
       "4  2015-03-03  MJ1311YNG6XKGA  Hitachi HDS5C3030ALA630    3.000593e+12   \n",
       "\n",
       "   failure  smart_1_normalized  smart_1_raw  smart_2_normalized  smart_2_raw  \\\n",
       "0        0               100.0          0.0               135.0        108.0   \n",
       "1        0               116.0  113638200.0                 NaN          NaN   \n",
       "2        0               119.0  210314536.0                 NaN          NaN   \n",
       "3        0               117.0  167638104.0                 NaN          NaN   \n",
       "4        0               100.0          0.0               135.0        108.0   \n",
       "\n",
       "   smart_3_normalized      ...        smart_250_normalized  smart_250_raw  \\\n",
       "0               141.0      ...                         NaN            NaN   \n",
       "1                93.0      ...                         NaN            NaN   \n",
       "2                91.0      ...                         NaN            NaN   \n",
       "3                95.0      ...                         NaN            NaN   \n",
       "4               140.0      ...                         NaN            NaN   \n",
       "\n",
       "   smart_251_normalized  smart_251_raw  smart_252_normalized  smart_252_raw  \\\n",
       "0                   NaN            NaN                   NaN            NaN   \n",
       "1                   NaN            NaN                   NaN            NaN   \n",
       "2                   NaN            NaN                   NaN            NaN   \n",
       "3                   NaN            NaN                   NaN            NaN   \n",
       "4                   NaN            NaN                   NaN            NaN   \n",
       "\n",
       "   smart_254_normalized  smart_254_raw  smart_255_normalized  smart_255_raw  \n",
       "0                   NaN            NaN                   NaN            NaN  \n",
       "1                   NaN            NaN                   NaN            NaN  \n",
       "2                   NaN            NaN                   NaN            NaN  \n",
       "3                   NaN            NaN                   NaN            NaN  \n",
       "4                   NaN            NaN                   NaN            NaN  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('2015_sample.csv')\n",
    "df = pd.concat([df,pd.read_csv('2015_failures.csv')])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smart_1_normalized</th>\n",
       "      <th>smart_3_normalized</th>\n",
       "      <th>smart_4_normalized</th>\n",
       "      <th>smart_5_normalized</th>\n",
       "      <th>smart_7_normalized</th>\n",
       "      <th>smart_12_normalized</th>\n",
       "      <th>smart_194_normalized</th>\n",
       "      <th>smart_197_normalized</th>\n",
       "      <th>smart_198_normalized</th>\n",
       "      <th>smart_199_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>100.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>105.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>119.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>120.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>119.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      smart_1_normalized  smart_3_normalized  smart_4_normalized  \\\n",
       "1241               100.0               122.0               100.0   \n",
       "320                105.0                92.0               100.0   \n",
       "1044               119.0                97.0               100.0   \n",
       "1171               120.0                91.0               100.0   \n",
       "786                119.0                91.0               100.0   \n",
       "\n",
       "      smart_5_normalized  smart_7_normalized  smart_12_normalized  \\\n",
       "1241               100.0               100.0                100.0   \n",
       "320                 98.0                79.0                100.0   \n",
       "1044               100.0                85.0                100.0   \n",
       "1171                94.0                89.0                100.0   \n",
       "786                 99.0                89.0                100.0   \n",
       "\n",
       "      smart_194_normalized  smart_197_normalized  smart_198_normalized  \\\n",
       "1241                 253.0                 100.0                 100.0   \n",
       "320                   33.0                  97.0                  97.0   \n",
       "1044                  29.0                 100.0                 100.0   \n",
       "1171                  28.0                 100.0                 100.0   \n",
       "786                   24.0                 100.0                 100.0   \n",
       "\n",
       "      smart_199_normalized  \n",
       "1241                 200.0  \n",
       "320                  200.0  \n",
       "1044                 200.0  \n",
       "1171                 200.0  \n",
       "786                  200.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_norm = df[['smart_1_normalized', 'smart_3_normalized', 'smart_4_normalized', 'smart_5_normalized',\n",
    "           'smart_7_normalized','smart_12_normalized', 'smart_194_normalized', \n",
    "           'smart_197_normalized', 'smart_198_normalized', 'smart_199_normalized']]\n",
    "df_norm.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_norm.dropna(0,thresh =10).dropna(1)\n",
    "y = df['failure'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2856,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, mean_absolute_error,accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "LightGBMError",
     "evalue": "Unknown objective type name: binary-logloss",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-662ff2a440cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnum_round\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mbst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_sets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0meval_set\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# construct booster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mbooster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, train_set, model_file, silent)\u001b[0m\n\u001b[0;32m   1453\u001b[0m                 \u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1454\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1455\u001b[1;33m                 ctypes.byref(self.handle)))\n\u001b[0m\u001b[0;32m   1456\u001b[0m             \u001b[1;31m# save reference to data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1457\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \"\"\"\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecode_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLightGBMError\u001b[0m: Unknown objective type name: binary-logloss"
     ]
    }
   ],
   "source": [
    "eval_set = lgb.Dataset(X_val, label=y_val)\n",
    "param = {'objective':'binary_logloss'}\n",
    "train_data = lgb.Dataset(X_train, label=y_train, params=param)\n",
    "\n",
    "num_round = 10\n",
    "bst = lgb.train(params=param, train_set=train_data, num_boost_round=10, valid_sets=[eval_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mix type of y not allowed, got types {'continuous', 'binary'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-e579620faa8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Classification Report: \\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Confusion Matrix: \\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nAccuracy\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits)\u001b[0m\n\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1421\u001b[1;33m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1422\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1423\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[1;34m(*ys)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys_types\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Mix type of y not allowed, got types %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mys_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0mlabel_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mys_types\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Mix type of y not allowed, got types {'continuous', 'binary'}"
     ]
    }
   ],
   "source": [
    "y_pred = bst.predict(X_test)\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"\\nAccuracy\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.38182779, 0.81232894, 0.57184301, 0.24571337, 0.42215589,\n",
       "       0.81232894, 0.6520011 , 0.25433684, 0.27584101, 0.57787945,\n",
       "       0.32930799, 0.42775562, 0.58985403, 0.52019513, 0.57787945,\n",
       "       0.60079724, 0.74679889, 0.67886624, 0.24571337, 0.4399132 ,\n",
       "       0.4823489 , 0.81232894, 0.56004556, 0.2759553 , 0.41271355,\n",
       "       0.44560694, 0.49907354, 0.56157101, 0.27584101, 0.41510507,\n",
       "       0.42775562, 0.81232894, 0.56468654, 0.42775562, 0.81232894,\n",
       "       0.59004218, 0.81232894, 0.27584101, 0.50281369, 0.47556215,\n",
       "       0.59523841, 0.38573268, 0.49745779, 0.45114758, 0.41271355,\n",
       "       0.65604243, 0.49274071, 0.27584101, 0.46246765, 0.30429316,\n",
       "       0.5231939 , 0.57621085, 0.5331862 , 0.31650631, 0.53619685,\n",
       "       0.2950779 , 0.69150475, 0.49536548, 0.50411803, 0.50554513,\n",
       "       0.52019513, 0.81232894, 0.53843962, 0.41271355, 0.5012763 ,\n",
       "       0.49404002, 0.47681171, 0.73360628, 0.56940114, 0.61265306,\n",
       "       0.65604243, 0.81232894, 0.54128251, 0.52429863, 0.37032389,\n",
       "       0.49286204, 0.57787945, 0.71347162, 0.81232894, 0.79637383,\n",
       "       0.27584101, 0.47681171, 0.49920207, 0.5192888 , 0.24571337,\n",
       "       0.52662445, 0.59004218, 0.52678061, 0.45127033, 0.41271355,\n",
       "       0.61245803, 0.51021391, 0.62599195, 0.2950779 , 0.69591895,\n",
       "       0.65604243, 0.65604243, 0.57833403, 0.25433684, 0.56940114,\n",
       "       0.52962734, 0.30429316, 0.53495845, 0.41584965, 0.52477478,\n",
       "       0.58365396, 0.73360628, 0.59004218, 0.54045133, 0.45127033,\n",
       "       0.27584101, 0.50281369, 0.27584101, 0.57014823, 0.24571337,\n",
       "       0.27584101, 0.45555414, 0.30429316, 0.41271355, 0.58550156,\n",
       "       0.61909611, 0.50716623, 0.48880164, 0.2759553 , 0.36741305,\n",
       "       0.60652732, 0.73360628, 0.5000577 , 0.60086889, 0.27584101,\n",
       "       0.61216991, 0.30429316, 0.3956891 , 0.66341659, 0.25935716,\n",
       "       0.27584101, 0.41357221, 0.59523841, 0.81232894, 0.24571337,\n",
       "       0.24571337, 0.45312644, 0.56131946, 0.40141388, 0.81232894,\n",
       "       0.65604243, 0.48987595, 0.24571337, 0.81232894, 0.49265785,\n",
       "       0.71417925, 0.41271355, 0.73360628, 0.49286204, 0.4871679 ,\n",
       "       0.41271355, 0.24571337, 0.57645254, 0.38220141, 0.41271355,\n",
       "       0.51365824, 0.27584101, 0.49329539, 0.51864215, 0.41764993,\n",
       "       0.54953023, 0.38220141, 0.6721907 , 0.66339741, 0.50716623,\n",
       "       0.48279992, 0.2950779 , 0.25433684, 0.56674621, 0.70204139,\n",
       "       0.52170334, 0.48025957, 0.30429316, 0.81232894, 0.27584101,\n",
       "       0.49745779, 0.69150475, 0.40827263, 0.41271355, 0.27584101,\n",
       "       0.27584101, 0.44357627, 0.24571337, 0.24571337, 0.81232894,\n",
       "       0.71177058, 0.50713663, 0.57675969, 0.48127644, 0.51952244,\n",
       "       0.58365396, 0.24571337, 0.59004218, 0.79535658, 0.48903277,\n",
       "       0.79535658, 0.69150475, 0.24571337, 0.53837117, 0.30608357,\n",
       "       0.81232894, 0.65604243, 0.47681171, 0.54295802, 0.4955055 ,\n",
       "       0.24571337, 0.50706021, 0.24571337, 0.43035425, 0.5231939 ,\n",
       "       0.65604243, 0.43689785, 0.73360628, 0.58365396, 0.41695602,\n",
       "       0.70404159, 0.54738927, 0.24571337, 0.57787945, 0.61817133,\n",
       "       0.24571337, 0.29987933, 0.53956855, 0.81232894, 0.30429316,\n",
       "       0.58374351, 0.54408715, 0.50837863, 0.58067507, 0.24571337,\n",
       "       0.67886624, 0.25433684, 0.44184601, 0.24571337, 0.62599195,\n",
       "       0.44700637, 0.68096326, 0.25935716, 0.4392536 , 0.62167523,\n",
       "       0.67886624, 0.58369096, 0.47348079, 0.67886624, 0.54046841,\n",
       "       0.25433684, 0.24571337, 0.49055772, 0.41271355, 0.25433684,\n",
       "       0.27584101, 0.69150475, 0.24571337, 0.51102217, 0.31928044,\n",
       "       0.542572  , 0.57787945, 0.65430344, 0.81232894, 0.47681171,\n",
       "       0.43213758, 0.24571337, 0.65604243, 0.71204084, 0.62524108,\n",
       "       0.69150475, 0.54565147, 0.54953023, 0.27584101, 0.78502067,\n",
       "       0.49544798, 0.74679889, 0.5282286 , 0.44865461, 0.24571337,\n",
       "       0.59004218, 0.44685651, 0.4076001 , 0.27584101, 0.62765964,\n",
       "       0.30429316, 0.58463315, 0.61265306, 0.57190746, 0.81232894,\n",
       "       0.27584101, 0.72520707, 0.45533128, 0.46211182, 0.56157101,\n",
       "       0.60105397, 0.59161233, 0.47154085, 0.81232894, 0.49218249,\n",
       "       0.50423802, 0.67886624, 0.58273928, 0.49920207, 0.47386207,\n",
       "       0.57769878, 0.24571337, 0.59330777, 0.65430344, 0.57787945,\n",
       "       0.51222802, 0.50023595, 0.27584101, 0.57558848, 0.65604243,\n",
       "       0.65430344, 0.46260173, 0.6913708 , 0.25433684, 0.50716623,\n",
       "       0.24571337, 0.62599195, 0.48080769, 0.81232894, 0.27584101,\n",
       "       0.25433684, 0.31928044, 0.70895994, 0.68934863, 0.73360628,\n",
       "       0.45845583, 0.55707469, 0.54953023, 0.56862385, 0.73360628,\n",
       "       0.56157101, 0.5018809 , 0.48810375, 0.50716623, 0.50062434,\n",
       "       0.4603812 , 0.27584101, 0.25433684, 0.81232894, 0.55571486,\n",
       "       0.44700637, 0.45312644, 0.42775562, 0.54821083, 0.59523841,\n",
       "       0.24571337, 0.50423802, 0.52019513, 0.2950779 , 0.33269125,\n",
       "       0.61135054, 0.55117293, 0.44116272, 0.79637383, 0.57657372,\n",
       "       0.6076627 , 0.24571337, 0.27584101, 0.6721907 , 0.50919148,\n",
       "       0.24571337, 0.58067507, 0.56468654, 0.52074741, 0.43591334,\n",
       "       0.30429316, 0.50879871, 0.57620052, 0.27584101, 0.27584101,\n",
       "       0.46169854, 0.27584101, 0.60079724, 0.69150475, 0.27584101,\n",
       "       0.81232894, 0.52019513, 0.65415609, 0.57787945, 0.65823344,\n",
       "       0.24571337, 0.27584101, 0.41271355, 0.27584101, 0.58067507,\n",
       "       0.54223835, 0.47772211, 0.27584101, 0.46247103, 0.57632379,\n",
       "       0.65823344, 0.57972313, 0.54565147, 0.45312644, 0.40957014,\n",
       "       0.39964905, 0.53532907, 0.24571337, 0.5517364 , 0.65767654,\n",
       "       0.44357627, 0.65604243, 0.27584101, 0.81232894, 0.55711361,\n",
       "       0.27584101, 0.58550156, 0.55102985, 0.69150475, 0.55511343,\n",
       "       0.27584101, 0.39225235, 0.58365396, 0.27584101, 0.47963182,\n",
       "       0.44865461, 0.65430344, 0.57810084, 0.55932495, 0.41271355,\n",
       "       0.69150475, 0.2950779 , 0.56849794, 0.51848762, 0.24571337,\n",
       "       0.27584101, 0.24571337, 0.4834977 , 0.61265306, 0.55321485,\n",
       "       0.56853295, 0.4392536 , 0.49548373, 0.2950779 , 0.24571337,\n",
       "       0.81232894, 0.58161792, 0.64409484, 0.65430344, 0.47681171,\n",
       "       0.45555414, 0.59791069, 0.65430344, 0.54801667, 0.73360628,\n",
       "       0.43764134, 0.25433684, 0.27584101, 0.2950779 , 0.58067507,\n",
       "       0.24571337, 0.27584101, 0.45422571, 0.56919541, 0.42980697,\n",
       "       0.24571337, 0.67886624, 0.69150475, 0.24571337, 0.4392536 ,\n",
       "       0.49286204, 0.58067507, 0.48207211, 0.24571337, 0.24571337,\n",
       "       0.47714975, 0.69150475, 0.46334233, 0.44593508, 0.49938975,\n",
       "       0.67886624, 0.43342176, 0.70535374, 0.61058586, 0.3572522 ,\n",
       "       0.57621085, 0.54276512, 0.54031003, 0.27584101, 0.81232894,\n",
       "       0.58858709, 0.58374351, 0.61245803, 0.24571337, 0.27584101,\n",
       "       0.74679889, 0.27584101, 0.46169854, 0.24571337, 0.27584101,\n",
       "       0.50931481, 0.38182779, 0.69150475, 0.25935716, 0.69150475,\n",
       "       0.81232894, 0.24571337, 0.41271355, 0.45127033, 0.24571337,\n",
       "       0.57190746, 0.60411258, 0.74679889, 0.50281369, 0.24571337,\n",
       "       0.50364269, 0.30429316, 0.65604243, 0.52728468, 0.50281369,\n",
       "       0.38939643, 0.41271355, 0.47681171, 0.27584101, 0.44865461,\n",
       "       0.4754574 , 0.58067507, 0.67886624, 0.52117528, 0.44865461,\n",
       "       0.50281369, 0.49109791, 0.40134191, 0.27584101, 0.30429316,\n",
       "       0.65430344, 0.44700637, 0.65430344, 0.27584101, 0.41271355,\n",
       "       0.5537089 , 0.4788636 , 0.69150475, 0.39362439, 0.36379246,\n",
       "       0.52019513, 0.50281369, 0.50281369, 0.46673705, 0.59180755,\n",
       "       0.30429316, 0.49580371, 0.73360628, 0.31650631, 0.59581356,\n",
       "       0.56870849, 0.67886624, 0.24571337, 0.81232894, 0.65604243,\n",
       "       0.44627723, 0.67886624, 0.70963356, 0.81232894, 0.50915595,\n",
       "       0.59004218, 0.25433684, 0.41271355, 0.65604243, 0.48957974,\n",
       "       0.50281369, 0.24571337, 0.46350872, 0.57787945, 0.24571337,\n",
       "       0.58985403, 0.53334504])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function train in module lightgbm.engine:\n",
      "\n",
      "train(params, train_set, num_boost_round=100, valid_sets=None, valid_names=None, fobj=None, feval=None, init_model=None, feature_name='auto', categorical_feature='auto', early_stopping_rounds=None, evals_result=None, verbose_eval=True, learning_rates=None, keep_training_booster=False, callbacks=None)\n",
      "    Perform the training with given parameters.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    params : dict\n",
      "        Parameters for training.\n",
      "    train_set : Dataset\n",
      "        Data to be trained.\n",
      "    num_boost_round: int, optional (default=100)\n",
      "        Number of boosting iterations.\n",
      "    valid_sets: list of Datasets or None, optional (default=None)\n",
      "        List of data to be evaluated during training.\n",
      "    valid_names: list of string or None, optional (default=None)\n",
      "        Names of ``valid_sets``.\n",
      "    fobj : callable or None, optional (default=None)\n",
      "        Customized objective function.\n",
      "    feval : callable or None, optional (default=None)\n",
      "        Customized evaluation function.\n",
      "        Should accept two parameters: preds, train_data.\n",
      "        For multi-class task, the preds is group by class_id first, then group by row_id.\n",
      "        If you want to get i-th row preds in j-th class, the access way is preds[j * num_data + i].\n",
      "        Note: should return (eval_name, eval_result, is_higher_better) or list of such tuples.\n",
      "        To ignore the default metric corresponding to the used objective,\n",
      "        set the ``metric`` parameter to the string ``\"None\"`` in ``params``.\n",
      "    init_model : string, Booster or None, optional (default=None)\n",
      "        Filename of LightGBM model or Booster instance used for continue training.\n",
      "    feature_name : list of strings or 'auto', optional (default=\"auto\")\n",
      "        Feature names.\n",
      "        If 'auto' and data is pandas DataFrame, data columns names are used.\n",
      "    categorical_feature : list of strings or int, or 'auto', optional (default=\"auto\")\n",
      "        Categorical features.\n",
      "        If list of int, interpreted as indices.\n",
      "        If list of strings, interpreted as feature names (need to specify ``feature_name`` as well).\n",
      "        If 'auto' and data is pandas DataFrame, pandas categorical columns are used.\n",
      "        All values in categorical features should be less than int32 max value (2147483647).\n",
      "        Large values could be memory consuming. Consider to use consecutive integers started from zero.\n",
      "        All negative values in categorical features will be treated as missing values.\n",
      "    early_stopping_rounds: int or None, optional (default=None)\n",
      "        Activates early stopping. The model will train until the validation score stops improving.\n",
      "        Validation score needs to improve at least every ``early_stopping_rounds`` round(s)\n",
      "        to continue training.\n",
      "        Requires at least one validation data and one metric.\n",
      "        If there's more than one, will check all of them. But the training data is ignored anyway.\n",
      "        If early stopping occurs, the model will add ``best_iteration`` field.\n",
      "    evals_result: dict or None, optional (default=None)\n",
      "        This dictionary used to store all evaluation results of all the items in ``valid_sets``.\n",
      "    \n",
      "        Example\n",
      "        -------\n",
      "        With a ``valid_sets`` = [valid_set, train_set],\n",
      "        ``valid_names`` = ['eval', 'train']\n",
      "        and a ``params`` = ('metric':'logloss')\n",
      "        returns: {'train': {'logloss': ['0.48253', '0.35953', ...]},\n",
      "        'eval': {'logloss': ['0.480385', '0.357756', ...]}}.\n",
      "    verbose_eval : bool or int, optional (default=True)\n",
      "        Requires at least one validation data.\n",
      "        If True, the eval metric on the valid set is printed at each boosting stage.\n",
      "        If int, the eval metric on the valid set is printed at every ``verbose_eval`` boosting stage.\n",
      "        The last boosting stage or the boosting stage found by using ``early_stopping_rounds`` is also printed.\n",
      "    \n",
      "        Example\n",
      "        -------\n",
      "        With ``verbose_eval`` = 4 and at least one item in evals,\n",
      "        an evaluation metric is printed every 4 (instead of 1) boosting stages.\n",
      "    learning_rates: list, callable or None, optional (default=None)\n",
      "        List of learning rates for each boosting round\n",
      "        or a customized function that calculates ``learning_rate``\n",
      "        in terms of current number of round (e.g. yields learning rate decay).\n",
      "    keep_training_booster : bool, optional (default=False)\n",
      "        Whether the returned Booster will be used to keep training.\n",
      "        If False, the returned value will be converted into _InnerPredictor before returning.\n",
      "        You can still use _InnerPredictor as ``init_model`` for future continue training.\n",
      "    callbacks : list of callables or None, optional (default=None)\n",
      "        List of callback functions that are applied at each iteration.\n",
      "        See Callbacks in Python API for more information.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    booster : Booster\n",
      "        The trained Booster model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(lgb.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "clf.fit(x_train,y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "plt.plot(tpr,fpr)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Anaconda3]",
   "language": "python",
   "name": "Python [Anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
