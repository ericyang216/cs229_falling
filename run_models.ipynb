{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def evaluation_metrics(y_pred, y_label, thresh=0.5):\n",
    "    true_pos = []\n",
    "    true_neg = []\n",
    "    false_pos = []\n",
    "    false_neg = []\n",
    "\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_label[i] < thresh and y_pred[i] < thresh:\n",
    "            true_neg.append(i)\n",
    "        elif y_label[i] > thresh and y_pred[i] > thresh:\n",
    "            true_pos.append(i)\n",
    "        elif y_label[i] < thresh and y_pred[i] > thresh:\n",
    "            false_pos.append(i)\n",
    "        elif y_label[i] > thresh and y_pred[i] < thresh:\n",
    "            false_neg.append(i)\n",
    "\n",
    "    TP = len(true_pos)\n",
    "    TN = len(true_neg)\n",
    "    FP = len(false_pos)\n",
    "    FN = len(false_neg)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_label, y_pred, pos_label=1)\n",
    "\n",
    "    eval = \\\n",
    "    {\n",
    "        'accuracy'  : (TP + TN) / (TP + TN + TN + FN) if (TP + TN + TN + FN) > 0 else 0, \n",
    "        'precision' : TP / (TP + FP) if (TP + FP) > 0 else 0,\n",
    "        'recall'    : TP / (TP + FN) if (TP + FN) > 0 else 0,\n",
    "        'f1'        : (2*TP) / (2*TP + FP + FN) if (TP + FP + FN) > 0 else 0,\n",
    "        'roc_auc'   : auc(fpr, tpr),\n",
    "        'fpr'       : fpr,\n",
    "        'tpr'       : tpr\n",
    "    }\n",
    "\n",
    "    return eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eric/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2069: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# *** LOAD DATA *** \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nominal_sample = pd.read_csv('2015_sample.csv')\n",
    "failure_sample = pd.read_csv('2015_failures.csv')\n",
    "\n",
    "# For further testing on data from the future\n",
    "future_nominal = pd.read_csv('2018_q1_sample.csv')\n",
    "future_failure = pd.read_csv('2018_q1_failures.csv')\n",
    "\n",
    "# nominal_sample = nominal_sample.dropna(axis=0, thresh=20).dropna(axis=1)\n",
    "# failure_sample = failure_sample.dropna(axis=0, thresh=20).dropna(axis=1)\n",
    "\n",
    "feature_columns = [ 'smart_1_normalized', 'smart_3_normalized', 'smart_4_normalized', 'smart_5_normalized',\n",
    "           'smart_7_normalized','smart_12_normalized', 'smart_194_normalized', \n",
    "           'smart_197_normalized', 'smart_198_normalized', 'smart_199_normalized']\n",
    "\n",
    "data_curr = pd.concat([nominal_sample, failure_sample])\n",
    "y_curr = data_curr['failure']\n",
    "x_curr = data_curr[feature_columns]\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_curr, y_curr, train_size=0.8, random_state=1)\n",
    "\n",
    "data_future = pd.concat([future_nominal, future_failure])\n",
    "y_future = data_future['failure']\n",
    "x_future = data_future[feature_columns]\n",
    "\n",
    "x_train = x_train.values\n",
    "x_val = x_val.values\n",
    "y_train = y_train.values\n",
    "y_val = y_val.values\n",
    "x_future = x_future.values\n",
    "y_future = y_future.values\n",
    "\n",
    "# *** LOAD DATA ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** MODELS ***\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "lr1 = LogisticRegression(solver='newton-cg')\n",
    "lr2 = LogisticRegression(solver='lbfgs')\n",
    "lr3 = LogisticRegression(solver='saga')\n",
    "lr4 = LogisticRegression(solver='sag')\n",
    "lr5 = LogisticRegression(solver='liblinear')\n",
    "\n",
    "svm_linear = svm.SVC(kernel='linear', gamma='scale', probability=True)\n",
    "svm_rbf = svm.SVC(kernel='rbf', gamma='scale', probability=True)\n",
    "svm_poly = svm.SVC(kernel='poly', gamma='scale', probability=True)\n",
    "svm_sig = svm.SVC(kernel='sigmoid', gamma='scale', probability=True)\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc100 = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "boost1 = GradientBoostingClassifier(loss='deviance')\n",
    "boost2 = GradientBoostingClassifier(loss='exponential')\n",
    "\n",
    "gnb = GaussianNB()\n",
    "ada = AdaBoostClassifier(gnb, algorithm=\"SAMME\", n_estimators=200)\n",
    "\n",
    "\n",
    "\n",
    "models = [lr1, lr2, lr3, lr4, lr5, svm_linear, svm_rbf, svm_poly, svm_sig, rfc, rfc100, boost1, boost2, ada]\n",
    "# *** MODELS ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** RUN MODELS ***\n",
    "\n",
    "for model in models:\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    pred_train = model.predict_proba(x_train)[:,1]\n",
    "    pred_val = model.predict_proba(x_val)[:,1]\n",
    "    \n",
    "    # pred_future = svm_linear.predict_proba(x_future)[:,1]\n",
    "    # pred_train\n",
    "    \n",
    "    eval = evaluation_metrics(pred_val, y_val)\n",
    "    print(\"Trained:  \", model)\n",
    "    print(\"Precision:\", eval['precision'])\n",
    "    print(\"Recall:   \", eval['recall'])\n",
    "    print(\"Accuracy: \", eval['accuracy'])\n",
    "    print(\"F1-Score: \", eval['f1'])\n",
    "    print(\"AuC:      \", eval['roc_auc'])\n",
    "    print(\"\")\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.plot(eval['fpr'], eval['tpr'], label='ROC curve (area = %0.2f)' % eval['roc_auc'])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.show()\n",
    "\n",
    "# *** RUN MODELS ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.680333\n",
      "Will train until validation_0-logloss hasn't improved in 100 rounds.\n",
      "[1]\tvalidation_0-logloss:0.6681\n",
      "[2]\tvalidation_0-logloss:0.65772\n",
      "[3]\tvalidation_0-logloss:0.647879\n",
      "[4]\tvalidation_0-logloss:0.638731\n",
      "[5]\tvalidation_0-logloss:0.630713\n",
      "[6]\tvalidation_0-logloss:0.623046\n",
      "[7]\tvalidation_0-logloss:0.616239\n",
      "[8]\tvalidation_0-logloss:0.610338\n",
      "[9]\tvalidation_0-logloss:0.60489\n",
      "[10]\tvalidation_0-logloss:0.599988\n",
      "[11]\tvalidation_0-logloss:0.595239\n",
      "[12]\tvalidation_0-logloss:0.590716\n",
      "[13]\tvalidation_0-logloss:0.587124\n",
      "[14]\tvalidation_0-logloss:0.583701\n",
      "[15]\tvalidation_0-logloss:0.580077\n",
      "[16]\tvalidation_0-logloss:0.577065\n",
      "[17]\tvalidation_0-logloss:0.574641\n",
      "[18]\tvalidation_0-logloss:0.572136\n",
      "[19]\tvalidation_0-logloss:0.569933\n",
      "[20]\tvalidation_0-logloss:0.56829\n",
      "[21]\tvalidation_0-logloss:0.566556\n",
      "[22]\tvalidation_0-logloss:0.564917\n",
      "[23]\tvalidation_0-logloss:0.562984\n",
      "[24]\tvalidation_0-logloss:0.561114\n",
      "[25]\tvalidation_0-logloss:0.559432\n",
      "[26]\tvalidation_0-logloss:0.558281\n",
      "[27]\tvalidation_0-logloss:0.557553\n",
      "[28]\tvalidation_0-logloss:0.556829\n",
      "[29]\tvalidation_0-logloss:0.556949\n",
      "[30]\tvalidation_0-logloss:0.556926\n",
      "[31]\tvalidation_0-logloss:0.557834\n",
      "[32]\tvalidation_0-logloss:0.55798\n",
      "[33]\tvalidation_0-logloss:0.558048\n",
      "[34]\tvalidation_0-logloss:0.557982\n",
      "[35]\tvalidation_0-logloss:0.557762\n",
      "[36]\tvalidation_0-logloss:0.557679\n",
      "[37]\tvalidation_0-logloss:0.557748\n",
      "[38]\tvalidation_0-logloss:0.557314\n",
      "[39]\tvalidation_0-logloss:0.558018\n",
      "[40]\tvalidation_0-logloss:0.558163\n",
      "[41]\tvalidation_0-logloss:0.559284\n",
      "[42]\tvalidation_0-logloss:0.559008\n",
      "[43]\tvalidation_0-logloss:0.560735\n",
      "[44]\tvalidation_0-logloss:0.560671\n",
      "[45]\tvalidation_0-logloss:0.562507\n",
      "[46]\tvalidation_0-logloss:0.562316\n",
      "[47]\tvalidation_0-logloss:0.562535\n",
      "[48]\tvalidation_0-logloss:0.562667\n",
      "[49]\tvalidation_0-logloss:0.56296\n",
      "[50]\tvalidation_0-logloss:0.563375\n",
      "[51]\tvalidation_0-logloss:0.565373\n",
      "[52]\tvalidation_0-logloss:0.56681\n",
      "[53]\tvalidation_0-logloss:0.568243\n",
      "[54]\tvalidation_0-logloss:0.568988\n",
      "[55]\tvalidation_0-logloss:0.570817\n",
      "[56]\tvalidation_0-logloss:0.627872\n",
      "[57]\tvalidation_0-logloss:0.62809\n",
      "[58]\tvalidation_0-logloss:0.630342\n",
      "[59]\tvalidation_0-logloss:0.631992\n",
      "[60]\tvalidation_0-logloss:0.631607\n",
      "[61]\tvalidation_0-logloss:0.632361\n",
      "[62]\tvalidation_0-logloss:0.632469\n",
      "[63]\tvalidation_0-logloss:0.632656\n",
      "[64]\tvalidation_0-logloss:0.634968\n",
      "[65]\tvalidation_0-logloss:0.636141\n",
      "[66]\tvalidation_0-logloss:0.635951\n",
      "[67]\tvalidation_0-logloss:0.636089\n",
      "[68]\tvalidation_0-logloss:0.636571\n",
      "[69]\tvalidation_0-logloss:0.637111\n",
      "[70]\tvalidation_0-logloss:0.63788\n",
      "[71]\tvalidation_0-logloss:0.639185\n",
      "[72]\tvalidation_0-logloss:0.639881\n",
      "[73]\tvalidation_0-logloss:0.640187\n",
      "[74]\tvalidation_0-logloss:0.642201\n",
      "[75]\tvalidation_0-logloss:0.642806\n",
      "[76]\tvalidation_0-logloss:0.644686\n",
      "[77]\tvalidation_0-logloss:0.645151\n",
      "[78]\tvalidation_0-logloss:0.646553\n",
      "[79]\tvalidation_0-logloss:0.647785\n",
      "[80]\tvalidation_0-logloss:0.648269\n",
      "[81]\tvalidation_0-logloss:0.651807\n",
      "[82]\tvalidation_0-logloss:0.652036\n",
      "[83]\tvalidation_0-logloss:0.707975\n",
      "[84]\tvalidation_0-logloss:0.708427\n",
      "[85]\tvalidation_0-logloss:0.709899\n",
      "[86]\tvalidation_0-logloss:0.710429\n",
      "[87]\tvalidation_0-logloss:0.711097\n",
      "[88]\tvalidation_0-logloss:0.711926\n",
      "[89]\tvalidation_0-logloss:0.712953\n",
      "[90]\tvalidation_0-logloss:0.713656\n",
      "[91]\tvalidation_0-logloss:0.715774\n",
      "[92]\tvalidation_0-logloss:0.716985\n",
      "[93]\tvalidation_0-logloss:0.770956\n",
      "[94]\tvalidation_0-logloss:0.771255\n",
      "[95]\tvalidation_0-logloss:0.771437\n",
      "[96]\tvalidation_0-logloss:0.771961\n",
      "[97]\tvalidation_0-logloss:0.772148\n",
      "[98]\tvalidation_0-logloss:0.771961\n",
      "[99]\tvalidation_0-logloss:0.772175\n",
      "[100]\tvalidation_0-logloss:0.772505\n",
      "[101]\tvalidation_0-logloss:0.772836\n",
      "[102]\tvalidation_0-logloss:0.772936\n",
      "[103]\tvalidation_0-logloss:0.773704\n",
      "[104]\tvalidation_0-logloss:0.774873\n",
      "[105]\tvalidation_0-logloss:0.775035\n",
      "[106]\tvalidation_0-logloss:0.776661\n",
      "[107]\tvalidation_0-logloss:0.777106\n",
      "[108]\tvalidation_0-logloss:0.778741\n",
      "[109]\tvalidation_0-logloss:0.778934\n",
      "[110]\tvalidation_0-logloss:0.780846\n",
      "[111]\tvalidation_0-logloss:0.781908\n",
      "[112]\tvalidation_0-logloss:0.781757\n",
      "[113]\tvalidation_0-logloss:0.785051\n",
      "[114]\tvalidation_0-logloss:0.785172\n",
      "[115]\tvalidation_0-logloss:0.789891\n",
      "[116]\tvalidation_0-logloss:0.838792\n",
      "[117]\tvalidation_0-logloss:0.838931\n",
      "[118]\tvalidation_0-logloss:0.839416\n",
      "[119]\tvalidation_0-logloss:0.840596\n",
      "[120]\tvalidation_0-logloss:0.840904\n",
      "[121]\tvalidation_0-logloss:0.842194\n",
      "[122]\tvalidation_0-logloss:0.842411\n",
      "[123]\tvalidation_0-logloss:0.842762\n",
      "[124]\tvalidation_0-logloss:0.843211\n",
      "[125]\tvalidation_0-logloss:0.843364\n",
      "[126]\tvalidation_0-logloss:0.843546\n",
      "[127]\tvalidation_0-logloss:0.843811\n",
      "[128]\tvalidation_0-logloss:0.843788\n",
      "Stopping. Best iteration:\n",
      "[28]\tvalidation_0-logloss:0.556829\n",
      "\n",
      "Trained:   AdaBoostClassifier(algorithm='SAMME',\n",
      "          base_estimator=GaussianNB(priors=None, var_smoothing=1e-09),\n",
      "          learning_rate=1.0, n_estimators=200, random_state=None)\n",
      "Precision: 0.7719298245614035\n",
      "Recall:    0.15658362989323843\n",
      "Accuracy:  0.3847072879330944\n",
      "F1-Score:  0.2603550295857988\n",
      "AuC:       0.6943476293551503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# *** SPECIAL MODEL: xgboost ***\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(objective ='reg:linear', \n",
    "                             max_depth = 10,\n",
    "                             silent = 1,\n",
    "                             learning_rate = 0.05,\n",
    "                             n_estimators = 1000)\n",
    "\n",
    "eval_set = [(x_val, y_val)]\n",
    "\n",
    "xgb.fit(x_train, y_train, early_stopping_rounds=100,eval_metric= 'logloss', eval_set=eval_set)\n",
    "\n",
    "pred_train = model.predict_proba(x_train)[:,1]\n",
    "pred_val = model.predict_proba(x_val)[:,1]\n",
    "\n",
    "# pred_future = svm_linear.predict_proba(x_future)[:,1]\n",
    "# pred_train\n",
    "\n",
    "eval = evaluation_metrics(pred_val, y_val)\n",
    "print(\"Trained:  \", model)\n",
    "print(\"Precision:\", eval['precision'])\n",
    "print(\"Recall:   \", eval['recall'])\n",
    "print(\"Accuracy: \", eval['accuracy'])\n",
    "print(\"F1-Score: \", eval['f1'])\n",
    "print(\"AuC:      \", eval['roc_auc'])\n",
    "print(\"\")\n",
    "\n",
    "# *** SPECIAL MODEL: xgboost ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
